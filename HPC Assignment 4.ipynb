{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNjmM5kekem2A/CS4eGGOti"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8k-PRXsgbua","executionInfo":{"status":"ok","timestamp":1744721892631,"user_tz":-330,"elapsed":11,"user":{"displayName":"Anushree Kolte","userId":"01713710611162199633"}},"outputId":"9d7d934d-5a8f-419d-f3de-01990d83708f"},"outputs":[{"output_type":"stream","name":"stdout","text":["bin    cuda\tcuda-12.5\t  etc\t include  libexec     man  sbin   src\n","colab  cuda-12\tdist_metrics.pxd  games  lib\t  LICENSE.md  opt  share\n"]}],"source":["!ls /usr/local"]},{"cell_type":"code","source":["!which nvcc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmmwPrQHg_AD","executionInfo":{"status":"ok","timestamp":1744721897218,"user_tz":-330,"elapsed":1004,"user":{"displayName":"Anushree Kolte","userId":"01713710611162199633"}},"outputId":"4586ba04-131f-43c8-c4ee-dee700a5a0a9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/cuda/bin/nvcc\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M2raqOQIhGVB","executionInfo":{"status":"ok","timestamp":1744721901611,"user_tz":-330,"elapsed":16,"user":{"displayName":"Anushree Kolte","userId":"01713710611162199633"}},"outputId":"d53a7724-d01b-4827-c52b-44abca5da0d2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr 15 12:58:18 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["**Vector Addition using CUDA**"],"metadata":{"id":"KL8KZe9XhW3j"}},{"cell_type":"code","source":["%%writefile vector_add.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","\n","#define N 1000000\n","\n","// CUDA Kernel to perform vector addition\n","__global__ void vectorAdd(int* A, int* B, int* C, int n) {\n","  int i = blockIdx.x * blockDim.x + threadIdx.x;\n","  if (i < n) {\n","    C[i] = A[i] + B[i];\n","  }\n","}\n","\n","// Fill array with random integers\n","void fillArray(int *arr, int n){\n","  for (int i = 0; i < n; i++) {\n","    arr[i] = rand() % 100;\n","  }\n","}\n","\n","int main() {\n","  int size = N * sizeof(int);\n","\n","  // Allocate memory on host\n","  int *h_A = (int*)malloc(size);\n","  int *h_B = (int*)malloc(size);\n","  int *h_C = (int*)malloc(size);\n","\n","  // Initialize arrays on host\n","  fillArray(h_A, N);\n","  fillArray(h_B, N);\n","\n","  // Allocate memory on device\n","  int *d_A, *d_B, *d_C;\n","  cudaMalloc((void**)&d_A, size);\n","  cudaMalloc((void**)&d_B, size);\n","  cudaMalloc((void**)&d_C, size);\n","\n","  // Copy data from host to device\n","  cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","  cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","  // Launch kernel on GPU\n","  int threadsPerBlock = 256;\n","  int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n","  vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n","\n","  // Copy result back to host\n","  cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n","\n","  // Print the first 10 elements of the result\n","  printf(\"Vector Addition Result (first 10 element):\\n\");\n","  for (int i = 0; i < 10; i++) {\n","    printf(\"%d + %d = %d\\n\", h_A[i], h_B[i], h_C[i]);\n","  }\n","\n","  // Free memory\n","  cudaFree(d_A);\n","  cudaFree(d_B);\n","  cudaFree(d_C);\n","  free(h_A);\n","  free(h_B);\n","  free(h_C);\n","\n","  return 0;\n","}"],"metadata":{"id":"EMHxYlwvhf-n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744721978449,"user_tz":-330,"elapsed":1418,"user":{"displayName":"Anushree Kolte","userId":"01713710611162199633"}},"outputId":"adf9e575-f72f-4d7a-fa1d-1aa73cdc7a63"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting vector_add.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 vector_add.cu -o vector_add"],"metadata":{"id":"Hi0TMkA5hBza","executionInfo":{"status":"ok","timestamp":1744721988893,"user_tz":-330,"elapsed":3659,"user":{"displayName":"Anushree Kolte","userId":"01713710611162199633"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!./vector_add"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsleC3-HiQwh","executionInfo":{"status":"ok","timestamp":1744722024731,"user_tz":-330,"elapsed":2122,"user":{"displayName":"Anushree Kolte","userId":"01713710611162199633"}},"outputId":"19fa7f37-5f22-483b-fc31-636df38db3c6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector Addition Result (first 10 element):\n","83 + 89 = 172\n","86 + 63 = 149\n","77 + 84 = 161\n","15 + 93 = 108\n","93 + 81 = 174\n","35 + 55 = 90\n","86 + 6 = 92\n","92 + 93 = 185\n","49 + 61 = 110\n","21 + 50 = 71\n"]}]},{"cell_type":"markdown","source":["**Matrix Multiplication using CUDA C**"],"metadata":{"id":"NU5JLJvoidH0"}},{"cell_type":"code","source":["%%writefile matrix_mul.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","\n","#define N 16\n","\n","// CUDA Kernel to perform matrix multiplication\n","__global__ void matrixMul(int *A, int *B, int *C, int width) {\n","  int row = blockIdx.y * blockDim.y + threadIdx.y;\n","  int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","  // Check for valid matrix indices within bounds\n","  if (row < width && col < width) {\n","    int sum = 0;\n","    for (int k = 0; k < width; ++k) {\n","      sum += A[row * width + k] * B[k * width + col];\n","    }\n","    C[row * width + col] = sum;\n","  }\n","}\n","\n","void fillMatrix(int *matrix, int width) {\n","  for (int i = 0; i < width * width; i++) {\n","    matrix[i] = rand() % 10;\n","  }\n","}\n","\n","void printMatrix(int *matrix, int width) {\n","  for (int i = 0; i < width; i++) {\n","    for (int j = 0; j < width; j++) {\n","      printf(\"%4d \", matrix[i * width + j]);\n","    }\n","    printf(\"\\n\");\n","  }\n","}\n","\n","int main() {\n","  int size = N * N * sizeof(int);\n","\n","  // Allocate memory on host\n","  int *h_A = (int*)malloc(size);\n","  int *h_B = (int*)malloc(size);\n","  int *h_C = (int*)malloc(size);\n","\n","  // Initialize matrices on host\n","  fillMatrix(h_A, N);\n","  fillMatrix(h_B, N);\n","\n","  // Allocate memory on device\n","  int *d_A, *d_B, *d_C;\n","  cudaMalloc((void**)&d_A, size);\n","  cudaMalloc((void**)&d_B, size);\n","  cudaMalloc((void**)&d_C, size);\n","\n","  // Copy data from host to device\n","  cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","  cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","  // Define grid and block dimensions\n","  dim3 dimBlock(16, 16);\n","  dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x, (N + dimBlock.x - 1) / dimBlock.x);\n","\n","  //Launch kernel on GPU\n","  matrixMul<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n","\n","  // Copy result back to host\n","  cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n","\n","  //Print results\n","  printf(\"Matrix A:\\n\");\n","  printMatrix(h_A, N);\n","  printf(\"\\nMatrix B:\\n\");\n","  printMatrix(h_B, N);\n","  printf(\"\\nMatrix C (A x B):\\n\");\n","  printMatrix(h_C, N);\n","\n","  //Free memory\n","  cudaFree(d_A);\n","  cudaFree(d_B);\n","  cudaFree(d_C);\n","  free(h_A);\n","  free(h_B);\n","  free(h_C);\n","\n","  return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LpP5d1cJiZsK","executionInfo":{"status":"ok","timestamp":1744722871521,"user_tz":-330,"elapsed":1055,"user":{"displayName":"Anushree Kolte","userId":"01713710611162199633"}},"outputId":"9f50d9a7-b08a-425c-ad38-82a61be41c36"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing matrix_mul.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 matrix_mul.cu -o matrix_mul"],"metadata":{"id":"a7keMQBGiZpc","executionInfo":{"status":"ok","timestamp":1744722893207,"user_tz":-330,"elapsed":1784,"user":{"displayName":"Anushree Kolte","userId":"01713710611162199633"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!./matrix_mul"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RMqc1-g0iZmP","executionInfo":{"status":"ok","timestamp":1744722913890,"user_tz":-330,"elapsed":699,"user":{"displayName":"Anushree Kolte","userId":"01713710611162199633"}},"outputId":"7f2e364b-3356-4c95-f8e2-36e06093da19"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix A:\n","   3    6    7    5    3    5    6    2    9    1    2    7    0    9    3    6 \n","   0    6    2    6    1    8    7    9    2    0    2    3    7    5    9    2 \n","   2    8    9    7    3    6    1    2    9    3    1    9    4    7    8    4 \n","   5    0    3    6    1    0    6    3    2    0    6    1    5    5    4    7 \n","   6    5    6    9    3    7    4    5    2    5    4    7    4    4    3    0 \n","   7    8    6    8    8    4    3    1    4    9    2    0    6    8    9    2 \n","   6    6    4    9    5    0    4    8    7    1    7    2    7    2    2    6 \n","   1    0    6    1    5    9    4    9    0    9    1    7    7    1    1    5 \n","   9    7    7    6    7    3    6    5    6    3    9    4    8    1    2    9 \n","   3    9    0    8    8    5    0    9    6    3    8    5    6    1    1    5 \n","   9    8    4    8    1    0    3    0    4    4    4    4    7    6    3    1 \n","   7    5    9    6    2    1    7    8    5    7    4    1    8    5    9    7 \n","   5    3    8    8    3    1    8    9    6    4    3    3    3    8    6    0 \n","   4    8    8    8    9    7    7    6    4    3    0    3    0    9    2    5 \n","   4    0    5    9    4    6    9    2    2    4    7    7    5    4    8    1 \n","   2    8    9    3    6    8    0    2    1    0    5    1    1    0    8    5 \n","\n","Matrix B:\n","   0    6    4    6    2    5    8    6    2    8    4    7    2    4    0    6 \n","   2    9    9    0    8    1    3    1    1    0    3    4    0    3    9    1 \n","   9    6    9    3    3    8    0    5    6    6    4    0    0    4    6    2 \n","   6    7    5    6    9    8    7    2    8    2    9    9    6    0    2    7 \n","   6    1    3    2    1    5    9    9    1    4    9    1    0    7    5    8 \n","   7    0    4    8    0    4    2    9    6    1    0    4    2    2    2    0 \n","   5    5    2    9    0    2    8    3    8    0    4    0    9    1    9    6 \n","   2    5    4    4    9    9    3    6    0    5    0    2    9    4    3    5 \n","   1    7    4    3    1    4    6    9    4    2    2    6    4    1    2    8 \n","   8    9    2    8    8    8    6    8    3    8    3    3    3    8    0    4 \n","   7    6    8    9    0    6    8    7    9    0    3    3    3    7    3    2 \n","   6    5    2    6    5    8    7    9    6    0    4    1    0    4    8    7 \n","   0    8    6    2    4    7    9    3    9    2    8    3    0    1    7    8 \n","   9    1    5    4    9    2    5    7    4    9    9    4    5    9    3    5 \n","   7    0    8    1    9    9    7    8    2    5    3    4    9    0    2    0 \n","   1    9    6    2    1    2    0    7    3    1    1    9    0    5    6    7 \n","\n","Matrix C (A x B):\n"," 373  374  376  323  307  351  359  466  334  231  305  289  235  273  340  359 \n"," 325  309  368  296  363  390  368  385  322  191  269  245  316  182  317  283 \n"," 425  421  454  318  412  465  412  521  369  269  351  323  240  273  364  371 \n"," 235  299  291  257  216  288  313  302  287  175  249  241  214  190  228  286 \n"," 384  382  365  377  355  442  414  434  361  249  323  270  243  260  297  334 \n"," 438  429  454  346  440  469  494  501  349  360  422  340  276  325  312  379 \n"," 282  464  408  320  325  422  435  416  350  220  332  327  254  256  327  413 \n"," 333  343  283  336  273  415  323  443  299  225  229  186  187  269  287  317 \n"," 365  552  490  410  319  488  512  533  433  262  378  367  242  337  415  472 \n"," 304  444  396  329  341  428  435  461  327  189  313  320  216  287  327  391 \n"," 285  401  359  290  333  354  407  342  323  240  337  286  190  232  275  329 \n"," 407  519  495  384  440  529  484  518  399  350  369  352  346  315  371  426 \n"," 400  392  392  363  405  461  439  450  350  314  351  269  352  274  309  377 \n"," 432  398  412  359  378  407  403  490  333  297  374  306  275  326  369  393 \n"," 432  356  374  417  324  467  483  472  427  235  355  265  306  250  317  355 \n"," 314  270  380  215  233  325  255  364  239  167  207  217  147  200  262  185 \n"]}]}]}